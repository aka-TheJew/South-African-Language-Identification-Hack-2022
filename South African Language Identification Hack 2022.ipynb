{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re \n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# Model building \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "import sklearn\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING & CONVERTING CSV FILES TO PANDAS DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test  = pd.read_csv('test_set.csv', skipinitialspace = True)\n",
    "df_train = pd.read_csv('train_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE - PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Disrtibution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xho    3000\n",
       "eng    3000\n",
       "nso    3000\n",
       "ven    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "tso    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chekcing the landguage Id data distribution\n",
    "# All classes have equal distribution \n",
    "df_train['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function.\n",
    "\n",
    "def CleanTweets(tweets):\n",
    "    # Converts from upper case to lower case\n",
    "    tweets = tweets.lower()\n",
    "    # removing numbers\n",
    "    tweets = re.sub(r'\\d+','',tweets)\n",
    "    # removes @ mentions \n",
    "    tweets = re.sub('@[\\w]*','',tweets)\n",
    "    # removes urls\n",
    "    tweets = re.sub(r'https?:\\/\\/.*\\/\\w*','',tweets)\n",
    "    # removes hashtags\n",
    "    tweets = re.sub(r'#\\w*','',tweets)\n",
    "    # removes punctuation\n",
    "    tweets = ''.join([l for l in tweets if l not in string.punctuation])   \n",
    "    # Removes extra white space\n",
    "    tweets = re.sub(r'\\s\\s+','',tweets)\n",
    "    # removes the newline characters [\\n] from pandas column\n",
    "    tweets = tweets.replace('\\n', ' ')\n",
    "    # removes space infront of tweet\n",
    "    tweets = tweets.strip()\n",
    "    tweets = tweets.lstrip()\n",
    "    return tweets\n",
    "df_train['text'] = df_train['text'].apply(CleanTweets)\n",
    "df_test['text']  = df_test['text'].apply(CleanTweets) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Id Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts the responce variable lables to numerical values\n",
    "\n",
    "def Language_to_num(df):\n",
    "    # Allocate lang_id column to variable language    \n",
    "    language = list(df['lang_id'])\n",
    "    text_to_num = []  # Initialize open list assigend to variable text_to_num\n",
    "\n",
    "    # Use for loop to assign numerical values to language Ids\n",
    "    for i in language  :\n",
    "        if i == 'xho'  :\n",
    "            text_to_num.append(1)\n",
    "        elif i == 'eng'    :\n",
    "            text_to_num.append(2)\n",
    "        elif i == 'nso'    :\n",
    "            text_to_num.append(3)\n",
    "        elif i == 'ven'    :\n",
    "            text_to_num.append(4)\n",
    "        elif i == 'tsn'    :\n",
    "            text_to_num.append(5)\n",
    "        elif i == 'nbl'    :\n",
    "            text_to_num.append(6)\n",
    "        elif i == 'zul'    :\n",
    "            text_to_num.append(7)\n",
    "        elif i == 'ssw'    :\n",
    "            text_to_num.append(8)\n",
    "        elif i == 'tso'    :\n",
    "            text_to_num.append(9)\n",
    "        elif i == 'sot'    :\n",
    "            text_to_num.append(10)\n",
    "        else :\n",
    "            text_to_num.append(11)\n",
    "            \n",
    "        # Convert text_to_num from list to tuple\n",
    "        def convert(list):\n",
    "            return tuple(list)\n",
    "        convert(text_to_num)\n",
    "        \n",
    "    # Assign values in lang_id column to new column language of df_test data frame\n",
    "    df_train['language'] = df_train['lang_id']\n",
    "    \n",
    "    # Assign values in text_to_num list to new Id column of df_test data frame\n",
    "    df['lang_id'] = text_to_num\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Initialize Language_to_num function to df_train data frame\n",
    "df_train = Language_to_num(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Vectorization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I TF-IDF Vectorizer [tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english', tokenizer= word_tokenize, analyzer='char', ngram_range=(1, 7)) \n",
    "\n",
    "# Fit and transform of train and test predictor feartures\n",
    "vect_train_tfidf = tfidf.fit_transform(df_train['text'])\n",
    "vect_test_tfidf  = tfidf.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II Count Vectorizer [cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer \n",
    "cv = CountVectorizer(min_df = 2  , max_df = 0.5, ngram_range =(1,2))\n",
    "\n",
    "# Fit and transform of train and test predictor feartures\n",
    "vect_train_cv = cv.fit_transform(df_train['text'])\n",
    "vect_test_cv  = cv.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN - TEST SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splitting\n",
    "X = vect_train_tfidf\n",
    "Y = df_train['lang_id']\n",
    "\n",
    "#Setting the train test ratio and assiging X,y(train, test) values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splitting\n",
    "X = vect_train_cv\n",
    "Y = df_train['lang_id']\n",
    "\n",
    "#Setting the train test ratio and assiging X,y(train, test) values\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       761\n",
      "           2       1.00      1.00      1.00       762\n",
      "           3       1.00      1.00      1.00       782\n",
      "           4       1.00      1.00      1.00       785\n",
      "           5       1.00      1.00      1.00       746\n",
      "           6       1.00      1.00      1.00       734\n",
      "           7       1.00      0.99      1.00       735\n",
      "           8       1.00      1.00      1.00       732\n",
      "           9       1.00      1.00      1.00       700\n",
      "          10       1.00      1.00      1.00       759\n",
      "          11       1.00      1.00      1.00       754\n",
      "\n",
      "    accuracy                           1.00      8250\n",
      "   macro avg       1.00      1.00      1.00      8250\n",
      "weighted avg       1.00      1.00      1.00      8250\n",
      "\n",
      "0.998660650859696\n"
     ]
    }
   ],
   "source": [
    "# Logistic Classifier\n",
    "# Classifier initialization, fit and prediction \n",
    "lc_tfidf = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', random_state = 42) \n",
    "lc_tfidf.fit(X_train, y_train)\n",
    "y_lc_tfidf = lc_tfidf.predict(X_test)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test, y_lc_tfidf))\n",
    "print(metrics.f1_score(y_test, y_lc_tfidf, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier [svc]\n",
    "# Classifier initialization, fit and prediction\n",
    "svc_tfidf = SVC(C = 10, gamma = 0.01)\n",
    "svc_tfidf.fit(X_train, y_train)\n",
    "y_svc_tfidf_pred = svc_tfidf.predict(X_test)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test, y_svc_tfidf_pred))\n",
    "print(metrics.f1_score(y_test, y_svc_tfidf_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       761\n",
      "           2       1.00      1.00      1.00       762\n",
      "           3       1.00      1.00      1.00       782\n",
      "           4       1.00      1.00      1.00       785\n",
      "           5       1.00      1.00      1.00       746\n",
      "           6       1.00      1.00      1.00       734\n",
      "           7       1.00      1.00      1.00       735\n",
      "           8       1.00      1.00      1.00       732\n",
      "           9       1.00      1.00      1.00       700\n",
      "          10       1.00      1.00      1.00       759\n",
      "          11       1.00      1.00      1.00       754\n",
      "\n",
      "    accuracy                           1.00      8250\n",
      "   macro avg       1.00      1.00      1.00      8250\n",
      "weighted avg       1.00      1.00      1.00      8250\n",
      "\n",
      "0.9996392021548123\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classifier Tweaked [mt] (Best Performing Model)\n",
    "# Classifier initialization, fit and prediction\n",
    "mt_tfidf = MultinomialNB(alpha = 0.002 , fit_prior = False )\n",
    "mt_tfidf.fit(X_train, y_train)\n",
    "y_mt_tfidf = mt_tfidf.predict(X_test)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test, y_mt_tfidf))\n",
    "print(metrics.f1_score(y_test, y_mt_tfidf, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDG Classifier [sgd]\n",
    "# Classifier initialization, fit and prediction\n",
    "sgd_tfidf = SGDClassifier(loss = \"hinge\", penalty = \"l2\", max_iter=10) \n",
    "sgd_tfidf.fit(X_train, y_train)\n",
    "y_sgd_tfidf = sgd_tfidf.predict(X_test)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test, y_sgd_tfidf))\n",
    "print(metrics.f1_score(y_test, y_sgd_tfidf, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC [lsvc]\n",
    "# Classifier initialization, fit and prediction\n",
    "lsvc_tfidf = LinearSVC()\n",
    "lsvc_tfidf.fit(X_train, y_train)\n",
    "y_lsvc_tfidf = lsvc_tfidf.predict(X_test)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test, y_lsvc_tfidf))\n",
    "print(metrics.f1_score(y_test, y_lsvc_tfidf, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Standard [ms]\n",
    "# Classifier initialization, fit and prediction\n",
    "ms_tfidf = MultinomialNB()\n",
    "ms_tfidf.fit(X_train, y_train)\n",
    "y_ms_tfidf = ms_tfidf.predict(X_test)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test, y_ms_tfidf))\n",
    "print(metrics.f1_score(y_test, y_ms_tfidf, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Classifier [lc]\n",
    "# Classifier initialization, fit and prediction\n",
    "lc_cv = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', random_state = 42) \n",
    "lc_cv.fit(X_train_cv, y_train_cv)\n",
    "y_lc_cv = lc_cv.predict(X_test_cv)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test_cv, y_lc_cv))\n",
    "print(metrics.f1_score(y_test, y_lc_cv, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier [svc]  \n",
    "# Classifier initialization, fit and prediction\n",
    "svc_cv = SVC(C = 10, gamma = 0.01)\n",
    "svc_cv.fit(X_train_cv, y_train_cv)\n",
    "y_svc_cv_pred = svc_cv.predict(X_test_cv)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test_cv, y_svc_cv_pred))\n",
    "print(metrics.f1_score(y_test, y_svc_cv_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miltinomial Tweeked [mt]\n",
    "# Classifier initialization, fit and prediction\n",
    "mt_cv = MultinomialNB(fit_prior=False)\n",
    "mt_cv.fit(X_train_cv, y_train_cv)\n",
    "y_mt_cv = mt_cv.predict(X_test_cv)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test_cv, y_mt_cv))\n",
    "print(metrics.f1_score(y_test, y_mt_cv, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Classifier [sgd]\n",
    "# Classifier initialization, fit and prediction\n",
    "sgd_cv = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=10) \n",
    "sgd_cv.fit(X_train_cv, y_train_cv)\n",
    "y_sgd_cv = sgd_cv.predict(X_test_cv)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test_cv, y_sgd_cv))\n",
    "print(metrics.f1_score(y_test, y_sgd_cv, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC [lsvc]\n",
    "# Classifier initialization, fit and prediction\n",
    "lsvc_cv = LinearSVC()\n",
    "lsvc_cv.fit(X_train_cv, y_train_cv)\n",
    "y_lsvc_cv = lsvc_cv.predict(X_test_cv)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test_cv, y_lsvc_cv))\n",
    "print(metrics.f1_score(y_test, y_lsvc_cv, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Standard [ms]\n",
    "# Classifier initialization, fit and prediction\n",
    "ms_cv = MultinomialNB()\n",
    "ms_cv.fit(X_train_cv, y_train_cv)\n",
    "y_ms_cv = ms_cv.predict(X_test_cv)\n",
    "\n",
    "# Displaying model performance metrics\n",
    "print(classification_report(y_test_cv, y_ms_cv))\n",
    "print(metrics.f1_score(y_test, y_ms_cv, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Classifier initialization and parameter setting\n",
    "estimators = [('lc_cv', lc_cv)]\n",
    "stack = StackingClassifier(estimators = estimators,\n",
    "                           final_estimator = LogisticRegression(C=20, class_weight='balanced', max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Classifier (Train, Test) fitting and ensemble model prediction\n",
    "stack.fit(X_train, y_train)\n",
    "y_pred_lc_cv = stack.predict(vect_test_cv)\n",
    "print(metrics.classification_report(y_test, y_pred_lc_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Refference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking sample submission format \n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of [Count Vectorizer] vectorized train and test predictor features\n",
    "vect_train_cv.shape, vect_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of [TF-IDF Vectorizer] vectorized train and test predictor features\n",
    "vect_train_tfidf.shape, vect_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Dataset predictor features\n",
    "y_pred_mt_tfidf = mt_tfidf.predict(vect_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function converts the responce feature predictions from\n",
    "numerical values to text values for anlaysis by the Kaggle auto-grader.\n",
    "'''\n",
    "\n",
    "def Num_to_language(var):    \n",
    "    # Initialize open list assigend to variable text_to_num\n",
    "    num = list(var) \n",
    "\n",
    "    # Allocate lang_id column to variable language    \n",
    "    language = []\n",
    "\n",
    "    # Use for loop to assign numerical values to language Ids\n",
    "    for i in num  :\n",
    "        \n",
    "        if i == 1  :\n",
    "            language.append('xho')\n",
    "        elif i == 2    :\n",
    "            language.append('eng')\n",
    "        elif i == 3    :\n",
    "            language.append('nso')\n",
    "        elif i == 4    :\n",
    "            language.append('ven')\n",
    "        elif i == 5    :\n",
    "            language.append('tsn')\n",
    "        elif i == 6    :\n",
    "            language.append('nbl')\n",
    "        elif i == 7    :\n",
    "            language.append('zul')\n",
    "        elif i == 8    :\n",
    "            language.append('ssw')\n",
    "        elif i == 9    :\n",
    "            language.append('tso')\n",
    "        elif i == 10    :\n",
    "            language.append('sot')\n",
    "        else :\n",
    "            language.append('afr')\n",
    "        \n",
    "    df_test['lang_id'] = language\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the predictions from the numbers to characters\n",
    "Num_to_language(y_pred_mt_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning df_test index column values to index variable\n",
    "index = df_test['index']\n",
    "# Assigning df_test lang_id column values to lang_id variable\n",
    "lang_id = df_test['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining index and prediction values into pandas dataframe and assigning them to a variable \n",
    "submission_mt_tfidf = pd.DataFrame({'index' : index, 'lang_id' : lang_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting submission file from dataframe to csv file format and downloading file to the directory\n",
    "submission_mt_tfidf.to_csv(\"Submission_mt_tfidf_v4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
